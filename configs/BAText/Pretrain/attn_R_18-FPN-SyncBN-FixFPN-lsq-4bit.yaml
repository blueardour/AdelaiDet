_BASE_: "Base-Pretrain.yaml"
MODEL:
  WEIGHTS: "output/batext/pretrain/attn_R_18-FPN_SyncBN-FixFPN/model_final.pth"
  RESNETS:
    DEPTH: 18
    RES2_OUT_CHANNELS: 64
    NORM: "SyncBN"
    STRIDE_IN_1X1: False
  BACKBONE:
    FREEZE_AT: 0
  FPN:
    NORM: "SyncBN-ReLU"
  BATEXT:
    NORM: "SyncBN"
    RECOGNIZER: "attn" 
  QUANTIZATION:
    scope: [
            'backbone.bottom_up.res2',
            'backbone.bottom_up.res3',
            'backbone.bottom_up.res4',
            'backbone.bottom_up.res5',
            # continue for more branch
            # FPN
            'backbone.fpn_lateral2',
            'backbone.fpn_output2',
            'backbone.fpn_lateral3',
            'backbone.fpn_output3',
            'backbone.fpn_lateral4',
            'backbone.fpn_output4',
            'backbone.fpn_lateral5',
            'backbone.fpn_output5',
            'backbone.top_block',
            # FCOS Head tower
            'proposal_generator.fcos_head.cls_tower',
            'proposal_generator.fcos_head.bbox_tower',
            # TextHead
            'roi_heads.CRNN'
           ]
    keyword: ["debug", "dorefa", "lsq"]
    padding_after_quant: True
    fm_enable: True 
    wt_enable: True 
    fm_bit: 4.0
    wt_bit: 4.0
    #fm_grad_type: "STE-scale"
    #wt_grad_type: "STE-scale"
    fm_boundary: 1.0
    wt_boundary: 1.0
    wt_quant_group: 1
    wt_adaptive: "var-mean"
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.01
  STEPS: (160000, 220000)
  MAX_ITER: 260000
  CHECKPOINT_PERIOD: 20000
TEST:
  EVAL_PERIOD: 20000
OUTPUT_DIR: "output/batext/pretrain/attn_R_18-FPN_SyncBN-FixFPN-lsq-4bit"

